{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2a7eenR1jpj"
   },
   "source": [
    "### Importing required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "mcLV5UtX1jIq"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_fSCbE12Hqz"
   },
   "source": [
    "### Getting, Preparing and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "HOnuJzWR2Rn_"
   },
   "outputs": [],
   "source": [
    "batch_size = 128 # The process of splitting the training dataset in n batches ( mini-batches)\n",
    "num_classes = 10 # initializing parameters\n",
    "epochs=12 #Epoch : one forward pass and one backward pass of all the training examples \n",
    "img_rows, img_cols = 28, 28  # the dimensions of one image (grey scale)\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data() # shape and load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rc9KXwAn2SVW",
    "outputId": "205a101f-ea7d-4de3-eab3-7f6709eee8de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape :  (60000, 28, 28, 1)\n",
      "x_test shape :  (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# define data formats between differet backends\n",
    "if k.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "\n",
    "#Normalization of data dimensions\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "print('x_train shape : ', x_train.shape)\n",
    "print('x_test shape : ', x_test.shape)\n",
    "\n",
    "# Convert class vector = labels to binary class matrices because the classification process is produced in binary time as we have 10 labels \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MUxmdM72Sq3"
   },
   "source": [
    "### Create Model : Outlining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNQVEzos2Uqd",
    "outputId": "1ea3368a-ed41-49c8-93d8-48e9b89320df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               1179776   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define the model\n",
    "model= Sequential() #initializing model\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape)) # the first layer is a convolutional layer with 32 filters\n",
    "model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) #Max Pooling #division\n",
    "model.add(Flatten()) #Flatten Layer is so important # to remove dimensions\n",
    "model.add(Dense(128, activation='relu')) #Fully connected layer with 128 neurons \n",
    "model.add(Dense(num_classes, activation='softmax')) # a layer related to binary classification \n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BTmbRbA2WPq"
   },
   "source": [
    "### Compile Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NH9sCWfE2Xzo"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8TVf-sk2Zmh"
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lz5rN5Gj2bJp",
    "outputId": "a5ea17b2-e011-421a-8ef6-c3df7af790b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 2.2718 - accuracy: 0.2026 - val_loss: 2.2161 - val_accuracy: 0.3611\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 2.1542 - accuracy: 0.4928 - val_loss: 2.0718 - val_accuracy: 0.6139\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 1.9733 - accuracy: 0.6652 - val_loss: 1.8377 - val_accuracy: 0.7238\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 1.6871 - accuracy: 0.7314 - val_loss: 1.4885 - val_accuracy: 0.7627\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 1.3208 - accuracy: 0.7655 - val_loss: 1.1170 - val_accuracy: 0.7948\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 1.0010 - accuracy: 0.7957 - val_loss: 0.8508 - val_accuracy: 0.8217\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.7926 - accuracy: 0.8183 - val_loss: 0.6905 - val_accuracy: 0.8405\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.6667 - accuracy: 0.8350 - val_loss: 0.5933 - val_accuracy: 0.8535\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5871 - accuracy: 0.8477 - val_loss: 0.5301 - val_accuracy: 0.8630\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.5334 - accuracy: 0.8574 - val_loss: 0.4866 - val_accuracy: 0.8716\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4950 - accuracy: 0.8651 - val_loss: 0.4550 - val_accuracy: 0.8772\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4662 - accuracy: 0.8711 - val_loss: 0.4306 - val_accuracy: 0.8816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08f0da8b20>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wGjIvF92crx"
   },
   "source": [
    "### Evaluate and test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBYj7TSO2e6p",
    "outputId": "82aac2b2-efef-4077-aaf0-41f1ec520f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.43061724305152893\n",
      "Test accuracy: 0.881600022315979\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CikqdlIP5go9"
   },
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FjATVnZl5jCa",
    "outputId": "79bfcc81-e28c-47bd-e6a1-03446a3ba570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model.h5\")\n",
    "print('saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFgc63JI2mMC"
   },
   "source": [
    "### Restoring Model and Making predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZAnW00Z22nq9",
    "outputId": "36c535d5-7dd9-45e6-b3ba-83126bdb1f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 132ms/step\n",
      "Predicted class: 2\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img as keras_load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load an image to make a prediction on\n",
    "\n",
    "def load_image(filename): # a function dedicated to preprocess the img after loading\n",
    "  img = keras_load_img(filename, target_size=(28, 28), color_mode=\"grayscale\")\n",
    "  img = img_to_array(img) # convert the image to a array\n",
    "  img = img.reshape(1,28,28,1) #reshaping the img to single sample with one channel \n",
    "  img = img.astype(\"float32\")\n",
    "  img = img/255.0\n",
    "  return img\n",
    "\n",
    "def run_example():\n",
    "  #loading_img\n",
    "  img = load_image(\"/content/sample_image.png\")\n",
    "  # loading the trained model\n",
    "  model = load_model(\"/content/model.h5\")\n",
    "  # Predict the class\n",
    "  result = model.predict(img) # make a prediction using the trained model\n",
    "  predicted_class = result.argmax(axis=-1)[0]\n",
    "  print('Predicted class:', predicted_class) # print the predicted class label \n",
    "\n",
    "#entry point, run the example\n",
    "run_example()\n",
    "\n",
    "\n",
    "\n",
    "#Note that we loaded a pullover image and the index of this label in the mnist dataset is actually 2. \n",
    "# the result proves that our prediction is correct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WY5IAuNu2pIO"
   },
   "source": [
    "### Improve Model's Predictive Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-mBu7AO2r7C",
    "outputId": "2deb305f-f054-4a86-a1d1-7301928767b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# We are going to change the parameters of our model by changing some parameters: \n",
    "# dense 128 ==> 100 , change the optimizer and number of epochs \n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "(trainX, trainY),(testX, testY) = fashion_mnist.load_data() # load the dataset\n",
    "# reshape dataset to have a single channel \n",
    "\n",
    "trainX = trainX.reshape((trainX.shape[0], 28,28,1))\n",
    "testX = testX.reshape((testX.shape[0], 28,28,1))\n",
    "#one hot encode target values\n",
    "trainY = to_categorical(trainY)\n",
    "testY = to_categorical(testY)\n",
    "#scale pixels and convert from integers to floats\n",
    "trainX=trainX.astype(\"float32\")\n",
    "testX = testX.astype(\"float32\")\n",
    "trainX=trainX / 255.0\n",
    "testX = testX / 255.0\n",
    "#define CNN model\n",
    "model= Sequential() #initializing model\n",
    "model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer =\"he_uniform\", input_shape=(28,28,1))) # the first layer is a convolutional layer with 32 filters\n",
    "model.add(MaxPooling2D((2,2))) #Max Pooling #division # feature Learning \n",
    "model.add(Flatten()) #Flatten Layer is so important # to remove dimensions\n",
    "model.add(Dense(100, activation='relu', kernel_initializer =\"he_uniform\")) #Fully connected layer with 128 neurons \n",
    "model.add(Dense(10, activation='softmax')) # a layer related to binary classification \n",
    "# compile model\n",
    "opt = SGD(lr=0.01,momentum=0.9)\n",
    "model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(trainX, trainY, batch_size=32, epochs=10, verbose=0)\n",
    "model.save(\"final_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ly9TMq6JX2P",
    "outputId": "8cee8c09-fdc3-48b3-b159-4e9b6d1c4309"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.30592867732048035\n",
      "Test accuracy: 0.9016000032424927\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the new model on the test set\n",
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "# we note that our model is improved based on hyper parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2-dHV5JKO7B"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
